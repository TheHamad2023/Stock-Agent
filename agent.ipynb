{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "790686f1",
   "metadata": {},
   "source": [
    "# Stock trading agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e6ff45",
   "metadata": {},
   "source": [
    "## Data\n",
    "We have a folder from https://www.kaggle.com/datasets/camnugent/sandp500 which includes the prices every market open day from 08-02-2013 to 08-02-2018 fro over 500 companies. These are companies in the S&P 500 and are the top 500 markets in the US, furthermore they represent the shares of the most commonly traded companies in the stock market.\n",
    "\n",
    "The data has 5 columns for each company in its own file named by its stock name:\n",
    "- Date: yy-mm-dd\n",
    "- Open: price of stock at market open\n",
    "- High: Highest price of stock in day\n",
    "- Low: Lowest price of stock in day\n",
    "- Close: Price of closing\n",
    "- Volume: How many stocks traded that day for that company\n",
    "- Name: The ticker name of the company in the stock market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7be6f8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in 'individual_stocks_5yr': 505\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def count_files(directory_path):\n",
    "    path = Path(directory_path)\n",
    "    count = len([p for p in path.iterdir() if p.is_file()])\n",
    "    return count\n",
    "\n",
    "directory = 'individual_stocks_5yr'\n",
    "file_count = count_files(directory)\n",
    "print(f\"Number of files in '{directory}': {file_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dfa555",
   "metadata": {},
   "source": [
    "### Reading the data\n",
    "Here we read the csv files for the first 100 companies and store the csv file in a panda dataframe and then store the 100 dataframes in a simple list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8bf3e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema: date | open | high | low | close | volume | name\n",
    "\n",
    "# import os\n",
    "\n",
    "# folder_path = 'individual_stocks_5yr'\n",
    "\n",
    "# entries = os.listdir(folder_path)\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# stock_prices = []\n",
    "\n",
    "# for i in range(100):\n",
    "#     filename = folder_path + \"/\" + entries[i]\n",
    "#     try:\n",
    "#         df = pd.read_csv(filename)\n",
    "#         stock_prices.append(df)\n",
    "#     except:\n",
    "#         print(\"Error: Error reading file (\" + filename + \")\")\n",
    "\n",
    "# # A vector with the days for conveinience later\n",
    "# calendar = stock_prices[0]['date']\n",
    "\n",
    "# # print(len(stock_prices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56bb8cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema: date | open | high | low | close | volume | name\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def read_data(folder_path, amount = None):\n",
    "    path = Path(folder_path)\n",
    "    files = []\n",
    "\n",
    "    for f in path.iterdir():\n",
    "        if f.is_file() and f.suffix.lower() == '.csv':\n",
    "            filename = f\n",
    "            try:\n",
    "                df = pd.read_csv(filename)\n",
    "                files.append(df)\n",
    "                if  amount:\n",
    "                    amount -= 1\n",
    "                    if amount == 0:\n",
    "                        return files\n",
    "            except:\n",
    "                print(\"Error: Error reading file (\" + filename + \")\")\n",
    "\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b026113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_data(comp_list):\n",
    "    def check_for_na(comp_df):\n",
    "        total_nas = comp_df.isna().sum().sum()\n",
    "        uniform = True\n",
    "\n",
    "        if total_nas != 0:\n",
    "            print(f\"Null values found. File: {comp_df.iat[0, 6]}. Count: {total_nas}\")\n",
    "            uniform = False\n",
    "        return uniform\n",
    "\n",
    "    def check_dfs_na(comp_list):\n",
    "        print(\"Checking for null values:\")\n",
    "        if comp_list:\n",
    "            for df in comp_list:\n",
    "                unifrom = check_for_na(df)\n",
    "        else:\n",
    "            print(\"Error: No dataframes in comp_list!\")\n",
    "    def check_length(comp_list):\n",
    "        print(\"Checking sizes:\")\n",
    "        default_shape = comp_list[0].shape\n",
    "        uniform = True\n",
    "\n",
    "        for i, df in enumerate(comp_list):\n",
    "            if df.shape != default_shape:\n",
    "                print(f\"Unequal size detected. Deffault: {default_shape}. Detected size: {df.shape} in file {df.iat[0, 6]}\")\n",
    "                uniform = False\n",
    "        if uniform:\n",
    "            print(\"All dfs same shape\")            \n",
    "\n",
    "    def check_dates(comp_list):\n",
    "        print(\"Checking for unequal dates:\")\n",
    "        calendar = comp_list[0]['date']\n",
    "        uniform = True\n",
    "\n",
    "        for i, df in enumerate(comp_list):\n",
    "            if not df['date'].equals(calendar):\n",
    "                print(f\"Unequal dates detected for file {df.iat[0, 6]}\")\n",
    "                uniform = False\n",
    "        if uniform:\n",
    "            print('All dates are equal')\n",
    "    \n",
    "    if not comp_list or len(comp_list) <= 1:\n",
    "            return\n",
    "    \n",
    "    check_dfs_na(comp_list)\n",
    "    check_length(comp_list)\n",
    "    check_dates(comp_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3f44fc",
   "metadata": {},
   "source": [
    "The above code shows that there are indeed Null values and unequal data for some companies in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ccb4569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(comp_list):\n",
    "    if not comp_list or len(comp_list) == 0:\n",
    "        print(\"Error: Input empty\")\n",
    "        return\n",
    "    \n",
    "    print(\"Cleaning dataframes from NaNs\")\n",
    "    counter = 0\n",
    "    clean_list = []\n",
    "\n",
    "    for df in comp_list:\n",
    "        if df.isnull().values.any():\n",
    "            print(f\"NaNs detected in {df.iat[0, 6]}, will be dropped\")\n",
    "            counter += 1\n",
    "        else:\n",
    "            clean_list.append(df)\n",
    "\n",
    "    print(f\"NaN dataframes dropped {counter}, will equalize length now.\")\n",
    "\n",
    "    min_days = 730\n",
    "    valid_companies = [df for df in clean_list if df.shape[0] >= min_days]\n",
    "\n",
    "    date_sets = [set(df['date']) for df in valid_companies]\n",
    "\n",
    "    common_dates = set.intersection(*date_sets)\n",
    "\n",
    "    aligned_dfs = [\n",
    "        df[df['date'].isin(common_dates)].sort_values('date').reset_index(drop=True)\n",
    "        for df in valid_companies\n",
    "    ]\n",
    "\n",
    "    return aligned_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0a895e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for null values:\n",
      "Null values found. File: WRK. Count: 3\n",
      "Null values found. File: FTV. Count: 3\n",
      "Null values found. File: ES. Count: 1\n",
      "Null values found. File: UA. Count: 3\n",
      "Null values found. File: DHR. Count: 4\n",
      "Null values found. File: O. Count: 4\n",
      "Null values found. File: VRTX. Count: 3\n",
      "Null values found. File: BHF. Count: 3\n",
      "Null values found. File: REGN. Count: 3\n",
      "Checking sizes:\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (975, 7) in file GOOG\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (781, 7) in file QRVO\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (1063, 7) in file ALLE\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (1257, 7) in file ORCL\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (917, 7) in file INFO\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (1257, 7) in file BMY\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (1197, 7) in file IQV\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (581, 7) in file HPQ\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (1169, 7) in file NWS\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (850, 7) in file CFG\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (662, 7) in file WRK\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (404, 7) in file FTV\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (276, 7) in file HLT\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (1249, 7) in file ES\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (1173, 7) in file COTY\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (1169, 7) in file FOXA\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (215, 7) in file DXC\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (561, 7) in file CSRA\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (1169, 7) in file FOX\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (464, 7) in file UA\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (1243, 7) in file DHR\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (655, 7) in file PYPL\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (1243, 7) in file O\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (888, 7) in file SYF\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (109, 7) in file DWDP\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (44, 7) in file APTV\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (143, 7) in file BHF\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (655, 7) in file KHC\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (1254, 7) in file ICE\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (1169, 7) in file NWSA\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (528, 7) in file WLTW\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (581, 7) in file HPE\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (297, 7) in file EVHC\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (960, 7) in file NAVI\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (152, 7) in file BHGE\n",
      "Checking for unequal dates:\n",
      "Unequal dates detected for file GOOG\n",
      "Unequal dates detected for file QRVO\n",
      "Unequal dates detected for file ALLE\n",
      "Unequal dates detected for file ORCL\n",
      "Unequal dates detected for file INFO\n",
      "Unequal dates detected for file BMY\n",
      "Unequal dates detected for file IQV\n",
      "Unequal dates detected for file HPQ\n",
      "Unequal dates detected for file NWS\n",
      "Unequal dates detected for file CFG\n",
      "Unequal dates detected for file WRK\n",
      "Unequal dates detected for file FTV\n",
      "Unequal dates detected for file HLT\n",
      "Unequal dates detected for file ES\n",
      "Unequal dates detected for file COTY\n",
      "Unequal dates detected for file FOXA\n",
      "Unequal dates detected for file DXC\n",
      "Unequal dates detected for file CSRA\n",
      "Unequal dates detected for file FOX\n",
      "Unequal dates detected for file UA\n",
      "Unequal dates detected for file DHR\n",
      "Unequal dates detected for file PYPL\n",
      "Unequal dates detected for file O\n",
      "Unequal dates detected for file SYF\n",
      "Unequal dates detected for file DWDP\n",
      "Unequal dates detected for file APTV\n",
      "Unequal dates detected for file BHF\n",
      "Unequal dates detected for file KHC\n",
      "Unequal dates detected for file ICE\n",
      "Unequal dates detected for file NWSA\n",
      "Unequal dates detected for file WLTW\n",
      "Unequal dates detected for file HPE\n",
      "Unequal dates detected for file EVHC\n",
      "Unequal dates detected for file NAVI\n",
      "Unequal dates detected for file BHGE\n"
     ]
    }
   ],
   "source": [
    "comp_list = (read_data(folder_path='individual_stocks_5yr', amount=500))\n",
    "inspect_data(comp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a41bb68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning dataframes from NaNs\n",
      "NaNs detected in WRK, will be dropped\n",
      "NaNs detected in FTV, will be dropped\n",
      "NaNs detected in ES, will be dropped\n",
      "NaNs detected in UA, will be dropped\n",
      "NaNs detected in DHR, will be dropped\n",
      "NaNs detected in O, will be dropped\n",
      "NaNs detected in VRTX, will be dropped\n",
      "NaNs detected in BHF, will be dropped\n",
      "NaNs detected in REGN, will be dropped\n",
      "NaN dataframes dropped 9, will equalize length now.\n",
      "Checking for null values:\n",
      "Checking sizes:\n",
      "All dfs same shape\n",
      "Checking for unequal dates:\n",
      "All dates are equal\n",
      "We now have: 479\n"
     ]
    }
   ],
   "source": [
    "clean_list = clean_data(comp_list)\n",
    "inspect_data(clean_list)\n",
    "comp_count = len(clean_list)\n",
    "print(f\"We now have: {len(clean_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75133f6d",
   "metadata": {},
   "source": [
    "Now all our data for all chosen companies are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "42a1644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum(comp_df, curr, n):\n",
    "    price_n_ago = comp_df.iat[curr - n, 4]\n",
    "\n",
    "    curr_price = comp_df.iat[curr, 4]\n",
    "            \n",
    "    return (curr_price - price_n_ago) / price_n_ago\n",
    "\n",
    "def get_momentums(comp_list, curr):\n",
    "    momentums = {}\n",
    "    n = 5\n",
    "    if curr < 5:\n",
    "        raise ValueError(\"Error: Current date is less than n!\")\n",
    "    \n",
    "\n",
    "    for comp in comp_list:\n",
    "        momentums[comp.iat[0][6]] = momentum(comp, curr, n)\n",
    "\n",
    "    return momentums\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6b558906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final cash: 101294.15250684899\n",
      "Unrealized value: 930652.0871796176\n",
      "Total portfolio value: 1031946.2396864666\n",
      "Total profit: 31946.239686466637\n"
     ]
    }
   ],
   "source": [
    "# num_days = clean_list[0].shape[0] - 1\n",
    "num_days = 100\n",
    "\n",
    "\n",
    "n = 8\n",
    "\n",
    "budget = 1000000\n",
    "purchase_amount = 1000\n",
    "\n",
    "purchases = {}\n",
    "sells = []\n",
    "\n",
    "momentum_day = []\n",
    "for i in range(num_days):\n",
    "    momentums = {}\n",
    "\n",
    "    for j in range(comp_count):\n",
    "        if i >= n:\n",
    "            comp_df = clean_list[j]\n",
    "\n",
    "            price_n_ago = comp_df.iat[i - n, 1]\n",
    "\n",
    "            curr_price = comp_df.iat[i, 1]\n",
    "\n",
    "            curr_date = comp_df.iat[i, 0]\n",
    "            \n",
    "            momentum = (curr_price - price_n_ago) / price_n_ago\n",
    "            stock_name = comp_df.iat[i, 6]\n",
    "            momentums[stock_name] = momentum\n",
    "            if momentum > 0 and budget > purchase_amount:\n",
    "                # Key is stock name, list contains [how many stocks purchased, price at purchase, purchase date]\n",
    "                new_purchase = [purchase_amount / curr_price, curr_price, curr_date]\n",
    "                if stock_name in purchases:\n",
    "                    purchases[stock_name].append(new_purchase)\n",
    "                else:\n",
    "                    purchases[stock_name] = [new_purchase, ]\n",
    "                budget -= purchase_amount\n",
    "\n",
    "            elif momentum < 0 and stock_name in purchases and purchases[stock_name]:\n",
    "                old_purchases = [purchase for purchase in purchases[stock_name]]\n",
    "\n",
    "                purchase_profit = 0\n",
    "                for old_purchase in old_purchases:\n",
    "                    purchase_profit += old_purchase[0] * curr_price\n",
    "                new_sell = {stock_name: [purchase_profit / curr_price, purchase_profit, curr_date]}\n",
    "                sells.append(new_sell)\n",
    "                del purchases[stock_name]\n",
    "                budget += purchase_profit\n",
    "    momentum_day.append(momentums)\n",
    "\n",
    "# print(budget)\n",
    "\n",
    "initial_budget = 1000000\n",
    "\n",
    "last_day_index = num_days - 1\n",
    "\n",
    "unrealized = 0\n",
    "for stock_name, buys in purchases.items():\n",
    "\n",
    "    comp_df = next(df for df in clean_list if df.iat[0, 6] == stock_name)\n",
    "    curr_price = comp_df.iat[last_day_index, 4]\n",
    "    \n",
    "    for qty, _, _ in buys:\n",
    "        unrealized += qty * curr_price\n",
    "\n",
    "portfolio_value = budget + unrealized\n",
    "profit = portfolio_value - initial_budget\n",
    "\n",
    "print(\"Final cash:\", budget)\n",
    "print(\"Unrealized value:\", unrealized)\n",
    "print(\"Total portfolio value:\", portfolio_value)\n",
    "print(\"Total profit:\", profit)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
