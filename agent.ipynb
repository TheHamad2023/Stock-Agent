{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "790686f1",
   "metadata": {},
   "source": [
    "# Stock trading agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e6ff45",
   "metadata": {},
   "source": [
    "## Data\n",
    "We have a folder from https://www.kaggle.com/datasets/camnugent/sandp500 which includes the prices every market open day from 08-02-2013 to 08-02-2018 fro over 500 companies. These are companies in the S&P 500 and are the top 500 markets in the US, furthermore they represent the shares of the most commonly traded companies in the stock market.\n",
    "\n",
    "The data has 5 columns for each company in its own file named by its stock name:\n",
    "- Date: yy-mm-dd\n",
    "- Open: price of stock at market open\n",
    "- High: Highest price of stock in day\n",
    "- Low: Lowest price of stock in day\n",
    "- Close: Price of closing\n",
    "- Volume: How many stocks traded that day for that company\n",
    "- Name: The ticker name of the company in the stock market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7be6f8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in 'individual_stocks_5yr': 505\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def count_files(directory_path):\n",
    "    path = Path(directory_path)\n",
    "    count = len([p for p in path.iterdir() if p.is_file()])\n",
    "    return count\n",
    "\n",
    "directory = 'individual_stocks_5yr'\n",
    "file_count = count_files(directory)\n",
    "print(f\"Number of files in '{directory}': {file_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dfa555",
   "metadata": {},
   "source": [
    "### Reading the data\n",
    "Here we read the csv files for the first 100 companies and store the csv file in a panda dataframe and then store the 100 dataframes in a simple list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8bf3e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema: date | open | high | low | close | volume | name\n",
    "\n",
    "# import os\n",
    "\n",
    "# folder_path = 'individual_stocks_5yr'\n",
    "\n",
    "# entries = os.listdir(folder_path)\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# stock_prices = []\n",
    "\n",
    "# for i in range(100):\n",
    "#     filename = folder_path + \"/\" + entries[i]\n",
    "#     try:\n",
    "#         df = pd.read_csv(filename)\n",
    "#         stock_prices.append(df)\n",
    "#     except:\n",
    "#         print(\"Error: Error reading file (\" + filename + \")\")\n",
    "\n",
    "# # A vector with the days for conveinience later\n",
    "# calendar = stock_prices[0]['date']\n",
    "\n",
    "# # print(len(stock_prices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56bb8cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema: date | open | high | low | close | volume | name\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def read_data(folder_path, amount = None):\n",
    "    path = Path(folder_path)\n",
    "    files = []\n",
    "\n",
    "    for f in path.iterdir():\n",
    "        if f.is_file() and f.suffix.lower() == '.csv':\n",
    "            filename = f\n",
    "            try:\n",
    "                df = pd.read_csv(filename)\n",
    "                files.append(df)\n",
    "                if  amount:\n",
    "                    amount -= 1\n",
    "                    if amount == 0:\n",
    "                        return files\n",
    "            except:\n",
    "                print(\"Error: Error reading file (\" + filename + \")\")\n",
    "\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b026113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_data(comp_list):\n",
    "    def check_for_na(comp_df):\n",
    "        total_nas = comp_df.isna().sum().sum()\n",
    "        uniform = True\n",
    "\n",
    "        if total_nas != 0:\n",
    "            print(f\"Null values found. File: {comp_df.iat[0, 6]}. Count: {total_nas}\")\n",
    "            uniform = False\n",
    "        return uniform\n",
    "\n",
    "    def check_dfs_na(comp_list):\n",
    "        print(\"Checking for null values:\")\n",
    "        if comp_list:\n",
    "            for df in comp_list:\n",
    "                unifrom = check_for_na(df)\n",
    "        else:\n",
    "            print(\"Error: No dataframes in comp_list!\")\n",
    "    def check_length(comp_list):\n",
    "        print(\"Checking sizes:\")\n",
    "        default_shape = comp_list[0].shape\n",
    "        uniform = True\n",
    "\n",
    "        for i, df in enumerate(comp_list):\n",
    "            if df.shape != default_shape:\n",
    "                print(f\"Unequal size detected. Deffault: {default_shape}. Detected size: {df.shape} in file {df.iat[0, 6]}\")\n",
    "                uniform = False\n",
    "        if uniform:\n",
    "            print(\"All dfs same shape\")            \n",
    "\n",
    "    def check_dates(comp_list):\n",
    "        print(\"Checking for unequal dates:\")\n",
    "        calendar = comp_list[0]['date']\n",
    "        uniform = True\n",
    "\n",
    "        for i, df in enumerate(comp_list):\n",
    "            if not df['date'].equals(calendar):\n",
    "                print(f\"Unequal dates detected for file {df.iat[0, 6]}\")\n",
    "                uniform = False\n",
    "        if uniform:\n",
    "            print('All dates are equal')\n",
    "    \n",
    "    if not comp_list or len(comp_list) <= 1:\n",
    "            return\n",
    "    \n",
    "    check_dfs_na(comp_list)\n",
    "    check_length(comp_list)\n",
    "    check_dates(comp_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3f44fc",
   "metadata": {},
   "source": [
    "The above code shows that there are indeed Null values and unequal data for some companies in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ccb4569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(comp_list):\n",
    "    if not comp_list or len(comp_list) == 0:\n",
    "        print(\"Error: Input empty\")\n",
    "        return\n",
    "    \n",
    "    print(\"Cleaning dataframes from NaNs\")\n",
    "    counter = 0\n",
    "    clean_list = []\n",
    "\n",
    "    for df in comp_list:\n",
    "        if df.isnull().values.any():\n",
    "            print(f\"NaNs detected in {df.iat[0, 6]}, will be dropped\")\n",
    "            counter += 1\n",
    "        else:\n",
    "            clean_list.append(df)\n",
    "\n",
    "    print(f\"NaN dataframes dropped {counter}, will equalize length now.\")\n",
    "\n",
    "    min_days = 730\n",
    "    valid_companies = [df for df in clean_list if df.shape[0] >= min_days]\n",
    "\n",
    "    date_sets = [set(df['date']) for df in valid_companies]\n",
    "\n",
    "    common_dates = set.intersection(*date_sets)\n",
    "\n",
    "    aligned_dfs = [\n",
    "        df[df['date'].isin(common_dates)].sort_values('date').reset_index(drop=True)\n",
    "        for df in valid_companies\n",
    "    ]\n",
    "\n",
    "    return aligned_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a895e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for null values:\n",
      "Null values found. File: WRK. Count: 3\n",
      "Null values found. File: FTV. Count: 3\n",
      "Checking sizes:\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (975, 7) in file GOOG\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (781, 7) in file QRVO\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (1063, 7) in file ALLE\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (1257, 7) in file ORCL\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (917, 7) in file INFO\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (1257, 7) in file BMY\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (1197, 7) in file IQV\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (581, 7) in file HPQ\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (1169, 7) in file NWS\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (850, 7) in file CFG\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (662, 7) in file WRK\n",
      "Unequal size detected. Deffault: (1259, 7). Detected size: (404, 7) in file FTV\n",
      "Checking for unequal dates:\n",
      "Unequal dates detected for file GOOG\n",
      "Unequal dates detected for file QRVO\n",
      "Unequal dates detected for file ALLE\n",
      "Unequal dates detected for file ORCL\n",
      "Unequal dates detected for file INFO\n",
      "Unequal dates detected for file BMY\n",
      "Unequal dates detected for file IQV\n",
      "Unequal dates detected for file HPQ\n",
      "Unequal dates detected for file NWS\n",
      "Unequal dates detected for file CFG\n",
      "Unequal dates detected for file WRK\n",
      "Unequal dates detected for file FTV\n"
     ]
    }
   ],
   "source": [
    "comp_list = (read_data(folder_path='individual_stocks_5yr', amount=200))\n",
    "inspect_data(comp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41bb68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning dataframes from NaNs\n",
      "NaNs detected in WRK, will be dropped\n",
      "NaNs detected in FTV, will be dropped\n",
      "NaN dataframes dropped 2, will equalize length now.\n",
      "Checking for null values:\n",
      "Checking sizes:\n",
      "All dfs same shape\n",
      "Checking for unequal dates:\n",
      "All dates are equal\n",
      "We now have: 197\n"
     ]
    }
   ],
   "source": [
    "clean_list = clean_data(comp_list)\n",
    "inspect_data(clean_list)\n",
    "comp_count = len(clean_list)\n",
    "print(f\"We now have: {len(clean_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75133f6d",
   "metadata": {},
   "source": [
    "Now all our data for all chosen companies are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a1644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum(comp_df, curr, n):\n",
    "    price_n_ago = comp_df.iat[curr - n, 4]\n",
    "\n",
    "    curr_price = comp_df.iat[curr, 4]\n",
    "            \n",
    "    return (curr_price - price_n_ago) / price_n_ago\n",
    "\n",
    "def get_momentums(comp_list, curr):\n",
    "    momentums = {}\n",
    "    n = 5\n",
    "    if curr < 5:\n",
    "        raise ValueError(\"Error: Current date is less than n!\")\n",
    "    \n",
    "\n",
    "    for comp in comp_list:\n",
    "        momentums[comp.iat[0][6]] = momentum(comp, curr, n)\n",
    "\n",
    "    return momentums\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "31fb7287",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stock_prices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_comp):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m:\n\u001b[0;32m---> 10\u001b[0m         comp_df \u001b[38;5;241m=\u001b[39m stock_prices[j]\n\u001b[1;32m     12\u001b[0m         price_n_ago \u001b[38;5;241m=\u001b[39m comp_df\u001b[38;5;241m.\u001b[39miat[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m     14\u001b[0m         curr_price \u001b[38;5;241m=\u001b[39m comp_df\u001b[38;5;241m.\u001b[39miat[i, \u001b[38;5;241m4\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stock_prices' is not defined"
     ]
    }
   ],
   "source": [
    "num_comp = 1\n",
    "num_days = 30\n",
    "\n",
    "n = 5\n",
    "for i in range(num_days):\n",
    "    momentums = {}\n",
    "\n",
    "    for j in range(num_comp):\n",
    "        if i >= 5:\n",
    "            comp_df = stock_prices[j]\n",
    "\n",
    "            price_n_ago = comp_df.iat[i - 5, 4]\n",
    "\n",
    "            curr_price = comp_df.iat[i, 4]\n",
    "            \n",
    "            momentums[comp_df.iat[i, 6]] = (curr_price - price_n_ago) / price_n_ago\n",
    "    \n",
    "    # print(momentums)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
